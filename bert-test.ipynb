{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"dockerImageVersionId":30529,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install keras_nlp","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:37:48.430065Z","iopub.execute_input":"2024-09-05T22:37:48.431083Z","iopub.status.idle":"2024-09-05T22:37:56.012223Z","shell.execute_reply.started":"2024-09-05T22:37:48.431044Z","shell.execute_reply":"2024-09-05T22:37:56.010864Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting keras_nlp\n  Downloading keras_nlp-0.6.1-py3-none-any.whl (573 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.5/573.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-text in /usr/local/lib/python3.8/site-packages (from keras_nlp) (2.12.1)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.8/site-packages (from keras_nlp) (1.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from keras_nlp) (23.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.8/site-packages (from keras_nlp) (13.4.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from keras_nlp) (1.23.5)\nCollecting regex\n  Downloading regex-2024.7.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (778 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.9/778.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting keras-core\n  Downloading keras_core-0.1.5-py3-none-any.whl (924 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.6/924.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting namex\n  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.8/site-packages (from keras-core->keras_nlp) (0.1.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.8/site-packages (from keras-core->keras_nlp) (3.9.0)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/site-packages (from rich->keras_nlp) (4.7.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.8/site-packages (from rich->keras_nlp) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/site-packages (from rich->keras_nlp) (2.15.1)\nRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/site-packages (from tensorflow-text->keras_nlp) (0.13.0)\nRequirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow-text->keras_nlp) (2.12.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.2.0)\nRequirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.4.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (57.5.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (4.23.4)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.12.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.32.0)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.12.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.4.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.16.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.6.3)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.14.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (16.0.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (23.5.26)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.12.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (3.3.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.56.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.3.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.40.0)\nRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.10.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.3.6)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (3.4.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.0.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.21.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.7.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.31.0)\nRequirement already satisfied: urllib3<2.0 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.26.16)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.3.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (5.3.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (6.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (2.1.3)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (3.15.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (0.5.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text->keras_nlp) (3.2.2)\nInstalling collected packages: namex, regex, keras-core, keras_nlp\nSuccessfully installed keras-core-0.1.5 keras_nlp-0.6.1 namex-0.0.8 regex-2024.7.24\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras_nlp\nimport matplotlib.pyplot as plt\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:37:56.014366Z","iopub.execute_input":"2024-09-05T22:37:56.014658Z","iopub.status.idle":"2024-09-05T22:37:58.018941Z","shell.execute_reply.started":"2024-09-05T22:37:56.014630Z","shell.execute_reply":"2024-09-05T22:37:58.017645Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using TensorFlow backend\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Accelerator","metadata":{}},{"cell_type":"code","source":" try:\n    # detect and init the TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    # instantiate a distribution strategy\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:\n    print(\"TPU not activated\")\n    strategy = tf.distribute.MirroredStrategy() # Works on CPU, single GPU and multiple GPUs in a single VM.\n    \nprint(\"replicas:\", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:37:58.020503Z","iopub.execute_input":"2024-09-05T22:37:58.020783Z","iopub.status.idle":"2024-09-05T22:38:06.482834Z","shell.execute_reply.started":"2024-09-05T22:37:58.020751Z","shell.execute_reply":"2024-09-05T22:38:06.481848Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nreplicas: 8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load the Contradictory, My Dear Watson dataset\nLet's have a look at all the data files\n\nThe training set contains a premise, a hypothesis, a label (0 = entailment, 1 = neutral, 2 = contradiction), and the language of the text. For more information about what these mean and how the data is structured, check out the data page: https://www.kaggle.com/c/contradictory-my-dear-watson/data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:38:06.484951Z","iopub.execute_input":"2024-09-05T22:38:06.485220Z","iopub.status.idle":"2024-09-05T22:38:06.595964Z","shell.execute_reply.started":"2024-09-05T22:38:06.485196Z","shell.execute_reply":"2024-09-05T22:38:06.594953Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           id                                            premise  \\\n0  5130fd2cb5  and these comments were considered in formulat...   \n1  5b72532a0b  These are issues that we wrestle with in pract...   \n2  3931fbe82a  Des petites choses comme celles-là font une di...   \n3  5622f0c60b  you know they can't really defend themselves l...   \n4  86aaa48b45  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...   \n\n                                          hypothesis lang_abv language  label  \n0  The rules developed in the interim were put to...       en  English      0  \n1  Practice groups are not permitted to work on t...       en  English      2  \n2              J'essayais d'accomplir quelque chose.       fr   French      0  \n3  They can't defend themselves because of their ...       en  English      0  \n4    เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร       th     Thai      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>lang_abv</th>\n      <th>language</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5130fd2cb5</td>\n      <td>and these comments were considered in formulat...</td>\n      <td>The rules developed in the interim were put to...</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5b72532a0b</td>\n      <td>These are issues that we wrestle with in pract...</td>\n      <td>Practice groups are not permitted to work on t...</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3931fbe82a</td>\n      <td>Des petites choses comme celles-là font une di...</td>\n      <td>J'essayais d'accomplir quelque chose.</td>\n      <td>fr</td>\n      <td>French</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5622f0c60b</td>\n      <td>you know they can't really defend themselves l...</td>\n      <td>They can't defend themselves because of their ...</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>86aaa48b45</td>\n      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n      <td>th</td>\n      <td>Thai</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"VALIDATION_SPLIT = 0.3\nTRAIN_SIZE = int(df_train.shape[0]*(1-VALIDATION_SPLIT))\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:38:06.596969Z","iopub.execute_input":"2024-09-05T22:38:06.597224Z","iopub.status.idle":"2024-09-05T22:38:06.601669Z","shell.execute_reply.started":"2024-09-05T22:38:06.597202Z","shell.execute_reply":"2024-09-05T22:38:06.600834Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Here's a utility function that splits the example into an `(x, y)` tuple that is suitable for `model.fit()`.\n\nBy default, `keras_nlp.models.BertClassifier` will tokenize and pack together raw strings using a `\"[SEP]\"` token during training.\n\nTherefore, this label splitting is all the data preparation that we need to perform.","metadata":{}},{"cell_type":"code","source":"def split_labels(x, y):\n    return (x[0], x[1]), y\n\n\ntraining_dataset = (\n    tf.data.Dataset.from_tensor_slices(\n        (\n            df_train[['premise','hypothesis']].values,\n            keras.utils.to_categorical(df_train['label'], num_classes=3)\n        )\n    )\n)\n\ntrain_dataset = training_dataset.take(TRAIN_SIZE)\nval_dataset = training_dataset.skip(TRAIN_SIZE)\n\ntrain_preprocessed = train_dataset.map(split_labels, tf.data.AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\nval_preprocessed = val_dataset.map(split_labels, tf.data.AUTOTUNE).batch(BATCH_SIZE, drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:38:06.602712Z","iopub.execute_input":"2024-09-05T22:38:06.602965Z","iopub.status.idle":"2024-09-05T22:38:06.696422Z","shell.execute_reply.started":"2024-09-05T22:38:06.602945Z","shell.execute_reply":"2024-09-05T22:38:06.695480Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Load a BERT model from Keras NLP - Train the model","metadata":{"execution":{"iopub.status.busy":"2023-07-31T05:23:02.390523Z","iopub.execute_input":"2023-07-31T05:23:02.390962Z","iopub.status.idle":"2023-07-31T05:23:02.396392Z","shell.execute_reply.started":"2023-07-31T05:23:02.390928Z","shell.execute_reply":"2023-07-31T05:23:02.394937Z"}}},{"cell_type":"code","source":"# Load a BERT model.\n\nwith strategy.scope():\n    classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_base_multi\", num_classes=3)\n\n    # in distributed training, the recommendation is to scale batch size and learning rate with the numer of workers.\n    classifier.compile(optimizer=keras.optimizers.Adam(1e-5*strategy.num_replicas_in_sync),\n                       loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n                       metrics=['accuracy'])\n    \n    classifier.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:38:06.697569Z","iopub.execute_input":"2024-09-05T22:38:06.697867Z","iopub.status.idle":"2024-09-05T22:38:37.415391Z","shell.execute_reply.started":"2024-09-05T22:38:06.697842Z","shell.execute_reply":"2024-09-05T22:38:37.414255Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_base_multi/v1/vocab.txt\n995526/995526 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/keras-nlp/models/bert_base_multi/v1/model.h5\n711647480/711647480 [==============================] - 3s 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"bert_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"bert_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ bert_tokenizer (\u001b[38;5;33mBertTokenizer\u001b[0m)                     │                                             \u001b[38;5;34m119,547\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ bert_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertTokenizer</span>)                     │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">119,547</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"bert_classifier\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_classifier\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ segment_ids (\u001b[38;5;33mInputLayer\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ bert_backbone (\u001b[38;5;33mBertBackbone\u001b[0m)                  │ {sequence_output: (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m),   │     \u001b[38;5;34m177,853,440\u001b[0m │\n│                                               │ pooled_output: (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)}            │                 │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                            │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ logits (\u001b[38;5;33mDense\u001b[0m)                                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                              │           \u001b[38;5;34m2,307\u001b[0m │\n└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                  </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ segment_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ bert_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)                  │ {sequence_output: (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>),   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">177,853,440</span> │\n│                                               │ pooled_output: (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)}            │                 │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,307</span> │\n└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m177,855,747\u001b[0m (678.47 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,855,747</span> (678.47 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m177,855,747\u001b[0m (678.47 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,855,747</span> (678.47 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train your own model - Fine-tuning BERT","metadata":{}},{"cell_type":"code","source":"EPOCHS=6\nhistory = classifier.fit(train_preprocessed,\n                         epochs=EPOCHS,\n                         validation_data=val_preprocessed)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:38:37.417061Z","iopub.execute_input":"2024-09-05T22:38:37.417365Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/6\n","output_type":"stream"},{"name":"stderr","text":"2024-09-05 22:39:15.860456: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2024-09-05 22:39:16.795551: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"66/66 [==============================] - ETA: 0s - loss: 0.9629 - accuracy: 0.5260","output_type":"stream"},{"name":"stderr","text":"2024-09-05 22:40:40.047498: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2024-09-05 22:40:40.315034: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"66/66 [==============================] - 124s 667ms/step - loss: 0.9629 - accuracy: 0.5260 - val_loss: 0.8495 - val_accuracy: 0.6177\nEpoch 2/6\n22/66 [=========>....................] - ETA: 15s - loss: 0.7857 - accuracy: 0.6555","output_type":"stream"}]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting accuracy\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(history_df['accuracy'], label='Training Accuracy')\nplt.plot(history_df['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy over epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plotting loss\nplt.subplot(1, 2, 2)\nplt.plot(history_df['loss'], label='Training Loss')\nplt.plot(history_df['val_loss'], label='Validation Loss')\nplt.title('Loss over epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\nTh","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}