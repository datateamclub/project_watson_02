{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font color='cornflowerblue'>Natural Language Inference Approach UM - Data Team Club","metadata":{}},{"cell_type":"markdown","source":"In the second UM Data Team Club project, we'll be diving into Natural Language Inference (NLI). Our goal is to explore and analyze the relationships between different text pairs to understand whether one sentence logically follows from another.","metadata":{}},{"cell_type":"markdown","source":"## Contents Table\n - [Imports](#1)\n - [Accelerator](#2)\n - [Load Data](#3)\n - [Data Exploring](#4)\n - [Data Preprocessing](#5)\n - [BERT Base Multi Model](#6)","metadata":{}},{"cell_type":"code","source":"# !pip install keras_nlp\n# !pip install seaborn\n# !pip install wordcloud","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:11.792924Z","iopub.execute_input":"2024-10-17T22:50:11.793388Z","iopub.status.idle":"2024-10-17T22:50:11.798958Z","shell.execute_reply.started":"2024-10-17T22:50:11.793346Z","shell.execute_reply":"2024-10-17T22:50:11.797533Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:11.801410Z","iopub.execute_input":"2024-10-17T22:50:11.802141Z","iopub.status.idle":"2024-10-17T22:50:11.812448Z","shell.execute_reply.started":"2024-10-17T22:50:11.802093Z","shell.execute_reply":"2024-10-17T22:50:11.811182Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"markdown","source":"### Imports <a id='1'></a>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nimport seaborn as sns\nsns.set_style('whitegrid')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:11.814591Z","iopub.execute_input":"2024-10-17T22:50:11.815056Z","iopub.status.idle":"2024-10-17T22:50:11.824424Z","shell.execute_reply.started":"2024-10-17T22:50:11.814994Z","shell.execute_reply":"2024-10-17T22:50:11.822958Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"### Accelerator <a id='2'></a>","metadata":{}},{"cell_type":"markdown","source":"### Load Data <a id='3'></a>","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\nprint(f\"Train dataset size: {df_train.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:11.826199Z","iopub.execute_input":"2024-10-17T22:50:11.826661Z","iopub.status.idle":"2024-10-17T22:50:11.907863Z","shell.execute_reply.started":"2024-10-17T22:50:11.826569Z","shell.execute_reply":"2024-10-17T22:50:11.906512Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"Train dataset size: (12120, 6)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Data Exploring <a id='4'></a>","metadata":{}},{"cell_type":"code","source":"df_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:11.910701Z","iopub.execute_input":"2024-10-17T22:50:11.911122Z","iopub.status.idle":"2024-10-17T22:50:11.927062Z","shell.execute_reply.started":"2024-10-17T22:50:11.911082Z","shell.execute_reply":"2024-10-17T22:50:11.925897Z"},"trusted":true},"execution_count":136,"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"           id                                            premise  \\\n0  5130fd2cb5  and these comments were considered in formulat...   \n1  5b72532a0b  These are issues that we wrestle with in pract...   \n2  3931fbe82a  Des petites choses comme celles-là font une di...   \n\n                                          hypothesis lang_abv language  label  \n0  The rules developed in the interim were put to...       en  English      0  \n1  Practice groups are not permitted to work on t...       en  English      2  \n2              J'essayais d'accomplir quelque chose.       fr   French      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>lang_abv</th>\n      <th>language</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5130fd2cb5</td>\n      <td>and these comments were considered in formulat...</td>\n      <td>The rules developed in the interim were put to...</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5b72532a0b</td>\n      <td>These are issues that we wrestle with in pract...</td>\n      <td>Practice groups are not permitted to work on t...</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3931fbe82a</td>\n      <td>Des petites choses comme celles-là font une di...</td>\n      <td>J'essayais d'accomplir quelque chose.</td>\n      <td>fr</td>\n      <td>French</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The NLI model will assign labels of 0, 1, or 2 (corresponding to entailment, neutral, and contradiction) to pairs of premises and hypotheses.","metadata":{}},{"cell_type":"markdown","source":"| <span style=\"color:cornflowerblue\">Label</span> | <span style=\"color:cornflowerblue\">Description</span>       |\n|---------------------------------------|---------------------------------------------------|\n| 0                                     | Entailment                                        |\n| 1                                     | Neutral                                           |\n| 2                                     | Contradiction                                     |\n","metadata":{}},{"cell_type":"markdown","source":"### Generative AI classification <a id='6'></a>","metadata":{"execution":{"iopub.status.busy":"2023-07-31T05:23:02.390523Z","iopub.execute_input":"2023-07-31T05:23:02.390962Z","iopub.status.idle":"2023-07-31T05:23:02.396392Z","shell.execute_reply.started":"2023-07-31T05:23:02.390928Z","shell.execute_reply":"2023-07-31T05:23:02.394937Z"}}},{"cell_type":"code","source":"#!pip install langchain\n#!pip install langchain_community","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:11.928650Z","iopub.execute_input":"2024-10-17T22:50:11.929097Z","iopub.status.idle":"2024-10-17T22:50:11.936321Z","shell.execute_reply.started":"2024-10-17T22:50:11.929056Z","shell.execute_reply":"2024-10-17T22:50:11.934917Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom transformers import pipeline\nfrom langchain.llms import HuggingFacePipeline\n\n# Pass the directory path where the model is stored on your system\n# -- model_name = \"google/flan-t5-large\"\n\n# Pass the namespace/repo_name to download the repo to your machine\nmodel_name = \"google/flan-t5-large\"\n\n# Initialize a tokenizer for the specified model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Initialize a model for sequence-to-sequence tasks using the specified pretrained model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:11.938127Z","iopub.execute_input":"2024-10-17T22:50:11.938724Z","iopub.status.idle":"2024-10-17T22:50:13.788197Z","shell.execute_reply.started":"2024-10-17T22:50:11.938609Z","shell.execute_reply":"2024-10-17T22:50:13.786966Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# Create a pipeline for text-to-text generation using a specified model and tokenizer\npipe = pipeline(\n    \"text2text-generation\",  # Specify the task as text-to-text generation\n    model=model,             # Use the previously initialized model\n    tokenizer=tokenizer,     # Use the previously initialized tokenizer\n    max_length=15,          # Set the maximum length for generated text to 512 tokens\n    temperature=0,           # Set the temperature parameter for controlling randomness (0 means deterministic)\n    top_p=0.95,              # Set the top_p parameter for controlling the nucleus sampling (higher values make output more focused)\n    repetition_penalty=1.15, # Set the repetition_penalty to control the likelihood of repeated words or phrases\n)\n\n# Create a Hugging Face pipeline for local language model (LLM) using the 'pipe' pipeline\nlocal_llm = HuggingFacePipeline(pipeline=pipe)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:13.790741Z","iopub.execute_input":"2024-10-17T22:50:13.791281Z","iopub.status.idle":"2024-10-17T22:50:13.798802Z","shell.execute_reply.started":"2024-10-17T22:50:13.791223Z","shell.execute_reply":"2024-10-17T22:50:13.797366Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# Ejemplo con 1 sola clasificacion \npremise = df_train[\"premise\"][100]\nhypothesis = df_train[\"hypothesis\"][100]\n\nprint(local_llm(f'''\nYou are given a premise and a hypothesis, classify the hypothesis based on the premise into: Entailment, Neutral or Contradiction.\nThe premise is {premise}, and the hypothesis to classify is {hypothesis}'''))","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:13.802708Z","iopub.execute_input":"2024-10-17T22:50:13.803357Z","iopub.status.idle":"2024-10-17T22:50:15.242850Z","shell.execute_reply.started":"2024-10-17T22:50:13.803293Z","shell.execute_reply":"2024-10-17T22:50:15.241571Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stdout","text":"Entailment\n","output_type":"stream"}]},{"cell_type":"code","source":"k = 150\nclasiff = []\nfor i in range(len(df_train.head(k))):\n    premise = df_train[\"premise\"][i]\n    hypothesis = df_train[\"hypothesis\"][i]\n    \n    pred = local_llm(f'''\n    You are given a premise and a hypothesis, classify the hypothesis based on the premise into: Entailment, Neutral or Contradiction.\n    The premise is {premise}, and the hypothesis to classify is {hypothesis}''')\n    \n    clasiff += [pred]","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:50:15.245093Z","iopub.execute_input":"2024-10-17T22:50:15.245532Z","iopub.status.idle":"2024-10-17T22:53:32.374010Z","shell.execute_reply.started":"2024-10-17T22:50:15.245486Z","shell.execute_reply":"2024-10-17T22:53:32.372516Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"clasiff[:15]","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:53:32.376391Z","iopub.execute_input":"2024-10-17T22:53:32.376834Z","iopub.status.idle":"2024-10-17T22:53:32.385293Z","shell.execute_reply.started":"2024-10-17T22:53:32.376789Z","shell.execute_reply":"2024-10-17T22:53:32.383593Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"['Entailment',\n 'Contradiction',\n 'Entailment',\n 'Entailment',\n 'Neutral',\n 'Neutral',\n 'Neutral',\n 'Contradiction',\n 'Neutral',\n 'Neutral',\n 'Contradiction',\n 'Neutral',\n 'Neutral',\n 'Neutral',\n 'Neutral']"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(len(clasiff)):\n    if clasiff[i] == \"Entailment\":\n        clasiff[i] = 0\n    elif clasiff[i] == \"Neutral\":\n        clasiff[i] = 1\n    else:\n        clasiff[i] = 2","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:53:32.386590Z","iopub.execute_input":"2024-10-17T22:53:32.387013Z","iopub.status.idle":"2024-10-17T22:53:32.399075Z","shell.execute_reply.started":"2024-10-17T22:53:32.386972Z","shell.execute_reply":"2024-10-17T22:53:32.397449Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"clasiff[:15]","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:53:32.400892Z","iopub.execute_input":"2024-10-17T22:53:32.401646Z","iopub.status.idle":"2024-10-17T22:53:32.417521Z","shell.execute_reply.started":"2024-10-17T22:53:32.401582Z","shell.execute_reply":"2024-10-17T22:53:32.416088Z"},"trusted":true},"execution_count":144,"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"[0, 2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1]"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nscore = accuracy_score(df_train.label.head(k), clasiff)\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:53:32.418989Z","iopub.execute_input":"2024-10-17T22:53:32.419407Z","iopub.status.idle":"2024-10-17T22:53:32.432571Z","shell.execute_reply.started":"2024-10-17T22:53:32.419369Z","shell.execute_reply":"2024-10-17T22:53:32.431200Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stdout","text":"0.6266666666666667\n","output_type":"stream"}]}]}